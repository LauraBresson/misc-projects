{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7abe79ff-057d-41fe-93d5-b7738694f665",
   "metadata": {},
   "source": [
    "# Mass extracting dashboard information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e18a516-e884-49dd-8c90-adc82907975b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing necessary modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pbixray import PBIXRay\n",
    "from datetime import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05aee9a8-5c1b-48ee-8d6f-049feeaf4d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a function to pass a variable name as text to be reused\n",
    "def get_var_name(var):\n",
    "    for name, value in globals().items():\n",
    "        if value is var:\n",
    "            return name\n",
    "\n",
    "# defining a function to mass write dataframes to excel\n",
    "def massWriting_toExcel(filename, dataframes, sheetnames):\n",
    "    with pd.ExcelWriter(f\"{filename}_{str(datetime.now().strftime('%Y-%b-%d.%H.%M'))}.xlsx\") as writer:\n",
    "        for df, sheet in zip(dataframes, sheetnames):\n",
    "            df.to_excel(writer, sheet_name=sheet, index=False)\n",
    "\n",
    "# defining a function to extract multiple file paths from a given folder and clean them for variable names uses\n",
    "def massPrint_fileMapping(path):\n",
    "    # Iterate over each file in the folder\n",
    "    for filename in os.listdir(path):\n",
    "        # Check if the file is a .pbix file\n",
    "        if filename.endswith('.pbix'):\n",
    "            # Get the full path of the file\n",
    "            file_path = os.path.join(path, filename)\n",
    "            var_name = filename.replace(' ', '_').replace('.pbix','').replace('&','').replace('-','').replace('__','_')\n",
    "            # print the code-ready variables along with their file path\n",
    "            print(f\"{var_name} = PBIXRay(r'{file_path}')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ab7be5-2cd3-4490-b61f-9c25c3644f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assigning the folder of interest to a variable\n",
    "folder_path = r'C:\\Users\\myname\\folder'\n",
    "\n",
    "# Iterate over each file in the folder\n",
    "massPrint_fileMapping(folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b07a58-00d4-409d-b062-2f38c15facc9",
   "metadata": {},
   "source": [
    "This function will output code-ready cleaned file paths in format `variable = PBIXRay(folder_path)` that can be used straight away by copy-paste into the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d666a06-6150-4154-a13b-7e21fd0b3244",
   "metadata": {},
   "outputs": [],
   "source": [
    "dashboard1 = PBIXRay(r'C:\\Users\\myname\\dashboard1.pbix')\n",
    "dashboard2 = PBIXRay(r'C:\\Users\\myname\\dashboard2.pbix')\n",
    "dashboard3 = PBIXRay(r'C:\\Users\\myname\\dashboard3.pbix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11610ff5-95cc-41b8-bd32-ba19a8d4a6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarly to the individual extraction file, grouping dataframes into a list \n",
    "# with sheet names in another list ready for zip later on\n",
    "pbix_files = [dashboard1, dashboard2, dashboard3]\n",
    "sheet_names = ['dashboard1', 'dashboard2', 'dashboard3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2c6930-1473-433c-b70b-fa12422d2657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# excel has a limit of 31 characters for its sheet names so need for verification\n",
    "# based on the result of the loop, correction can be made to the sheet names list above\n",
    "for i in sheet_names:\n",
    "    if len(i) > 31:\n",
    "        print(i, \": \", len(i) - 31, \"characters to be removed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321d6515-af6d-473d-a06b-90d4aa260cbd",
   "metadata": {},
   "source": [
    "Now that the two lists are ready, the documentation can begin.\n",
    "\n",
    "Compared to the individual extraction process where all information is extracted at once into one excel file, this process extracts the same information for all dashboards to export into an excel file. So for example, all metadata is extracted at once, or all queries are extracted at once.\n",
    "\n",
    "The metadata can be extracted altogether into one tab thanks to its simple format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fc67ce-f061-48c0-a61e-eb45d4639049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a list to hold dataframe information on metadata\n",
    "global_metadata = []\n",
    "\n",
    "# looping through the dashboards to extract the metadata\n",
    "for i in pbix_files:\n",
    "    model_info = {}\n",
    "    model_info['name'] = get_var_name(i)\n",
    "    model_info['Mb_size'] = round(i.size / 1e+6, 2)\n",
    "    metadata = i.metadata.sort_values(by= 'Name')\n",
    "    model_info['desktop_version'] = metadata.iloc[0, 1]\n",
    "    model_info['TimeIntelligence_Enabled'] = metadata.iloc[2, 1]\n",
    "    model_info['queries'] = metadata.iloc[1, 1]\n",
    "    global_metadata.append(model_info)\n",
    "\n",
    "# consolidating the looped extractions into a dataframe that can be exported\n",
    "global_metadata = pd.DataFrame(global_metadata).sort_values(by= 'name')\n",
    "global_metadata.to_csv(\"Metadata.csv\", index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01885d6e-68cd-4825-b0d7-9875ec21cb69",
   "metadata": {},
   "source": [
    "The format to follow to mass extract is as follows:\n",
    "1. defining a dictionary to store the dataframes further created in the process\n",
    "2. looping through the dashboards with one measure to analyze (example below is looking for DAX measures)\n",
    "3. stripping the dataframes of metadata to focus on their values of interest\n",
    "4. exporting to excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4d4dec-41fd-4e73-b159-5a4cbd40ab8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store DataFrames for each value in pbix_files\n",
    "global_measures = {}\n",
    "\n",
    "for i, pbix_file in enumerate(pbix_files):\n",
    "    model_measures = pbix_file.dax_measures\n",
    "    # Create a DataFrame for each value of i and store it in the dictionary\n",
    "    global_measures[f\"{pbix_file}\"] = pd.DataFrame(model_measures)\n",
    "\n",
    "global_measures = list(global_measures.values())\n",
    "\n",
    "massWriting_toExcel(\"measures\",\n",
    "                    dataframes= global_measures,\n",
    "                    sheetnames= sheet_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
